import pickle
import random
import numpy as np
import faiss
import os
from langchain_community.vectorstores import FAISS
from ai_core.llm.llm_utils import embedding_model
from typing import List, Dict, Any
from langchain_core.documents import Document

# ë°ì´í„° íŒŒì¼ ê²½ë¡œ ì„¤ì •
BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
DATA_DIR = os.path.join(BASE_DIR, "data")

# ê¸°ì¨, ì„¤ë ˜, ë³´í†µ, ìŠ¬í””, ë¶ˆì•ˆ, ë¶„ë…¸


# ë­ì²´ì¸ ê¸°ë°˜ ë²¡í„°db (faiss) ğŸ’•
# Faiss ì¸ë±ìŠ¤ì™€ ê°ì • ë°ì´í„° ë¡œë“œ
try:
    vectordb = FAISS.load_local("ai_core/vector_db/emotion_vectordb", embedding_model, allow_dangerous_deserialization = True)

    IS_DB_READY = True

    print("ë²¡í„° DBê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")

    with open(os.path.join(DATA_DIR, "emotion_data.pkl"), "rb") as f:
        db_data = pickle.load(f)
    EMOTIONS = db_data["emotions"]
    EMOTION_DATA = db_data["data"]
 
except Exception as e:
    vectordb = None
    IS_DB_READY = False
    print("ì˜¤ë¥˜: vectordb(langchain-faiss)ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € mk_data_db.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ë²¡í„°DBë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")
    print(f"ìƒì„¸ ì˜¤ë¥˜: {e}")


# ì˜ˆì‹œ ê²€ìƒ‰ í•¨ìˆ˜
# ê°ì •, ëŒ€í™”ë‚´ìš©ì— ëŒ€í•œ ê´€ë ¨ ë¬¸ì„œ ì¶”ì²œ
def get_recommendation_by_emotion(emotion_query: str, conversation: str = "", k: int = 3)-> List[Document]:
    
    if not IS_DB_READY:
        raise RuntimeError("ë²¡í„°DBê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    query = f"í˜„ì¬ ê°ì • : {emotion_query}\n ì‚¬ìš©ì ëŒ€í™” ë‚´ìš© : {conversation}"

    # queryì™€ ìœ ì‚¬í•œ ë¬¸ì„œ ì°¾ê¸° (rag)
    docs : List[Document] = vectordb.similarity_search(query, k=k)

    results: List[Document]
    results = vectordb.similarity_search(emotion_query, k=k)

    return results




def find_dissimilar_emotion_key(vector: np.ndarray) -> str:

    """
    ì£¼ì–´ì§„ ë²¡í„°ì™€ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ê°€ ê°€ì¥ ë‚®ì€ ê°ì • í‚¤ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
    Faissì˜ IndexFlatIPëŠ” ë‚´ì (dot product)ì„ ê³„ì‚°í•˜ë¯€ë¡œ, ì •ê·œí™”ëœ ë²¡í„°ë“¤ ì‚¬ì´ì—ì„œëŠ”
    ë‚´ì ì´ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ì™€ ê°™ìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ê°€ì¥ ì‘ì€ ê°’ì„ ì°¾ìœ¼ë©´ ë©ë‹ˆë‹¤.
    """
    if not IS_DB_READY:
        raise ConnectionError("ë²¡í„° DBê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    # ì…ë ¥ ë²¡í„° ì •ê·œí™”
    query_vector = np.array([vector]).astype('float32')
    faiss.normalize_L2(query_vector)

    # ê°€ì¥ ë‚®ì€ ìœ ì‚¬ë„(ê°€ì¥ ë¨¼ ê±°ë¦¬)ë¥¼ ê°€ì§„ ë²¡í„° 1ê°œë¥¼ ê²€ìƒ‰
    # k=len(EMOTIONS)ë¡œ ì „ì²´ë¥¼ ê²€ìƒ‰í•œ ë’¤, ì²«ë²ˆì§¸(ìê¸° ìì‹ )ë¥¼ ì œì™¸í•˜ê³  ì„ íƒí•  ìˆ˜ë„ ìˆìŒ
    # ì—¬ê¸°ì„œëŠ” ê°€ì¥ ë‚®ì€ í•˜ë‚˜ë§Œ ì°¾ìŠµë‹ˆë‹¤.
    distances, indices = vectordb.search(query_vector, k=1)
    
    # IndexFlatIPëŠ” ìµœëŒ€ ë‚´ì ì„ ì°¾ìœ¼ë¯€ë¡œ, kë¥¼ ëŠ˜ë ¤ ê°€ì¥ ë‚®ì€ ê°’ì„ ì°¾ì•„ì•¼ í•©ë‹ˆë‹¤.
    # ëª¨ë“  ë²¡í„°ì™€ì˜ ê±°ë¦¬ë¥¼ ê³„ì‚°í•˜ê³  ê°€ì¥ ì‘ì€ ê°’ì„ ì„ íƒí•©ë‹ˆë‹¤.
    distances, indices = vectordb.search(query_vector, k=len(EMOTIONS))

    # ê²€ìƒ‰ ê²°ê³¼ëŠ” ìœ ì‚¬ë„ê°€ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬ë˜ë¯€ë¡œ, ê°€ì¥ ë§ˆì§€ë§‰ ì¸ë±ìŠ¤ê°€ ìœ ì‚¬ë„ê°€ ê°€ì¥ ë‚®ì€ ë²¡í„°ì…ë‹ˆë‹¤.
    dissimilar_index = indices[0][-1]

    return EMOTIONS[dissimilar_index]

def get_random_content(emotion_key: str) -> dict:
    """ì£¼ì–´ì§„ ê°ì • í‚¤ì— í•´ë‹¹í•˜ëŠ” ì½˜í…ì¸  ì¤‘ í•˜ë‚˜ë¥¼ ë¬´ì‘ìœ„ë¡œ ì„ íƒí•©ë‹ˆë‹¤."""
    if not IS_DB_READY:
        raise ConnectionError("ë²¡í„° DBê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
    content_pool = EMOTION_DATA.get(emotion_key, {})
    if not content_pool:
        return {"error": "ì¶”ì²œí•  ì½˜í…ì¸ ê°€ ì—†ìŠµë‹ˆë‹¤."}

    content_type = random.choice(list(content_pool.keys()))
    content_item = random.choice(content_pool[content_type])
    
    return {content_type: content_item}
