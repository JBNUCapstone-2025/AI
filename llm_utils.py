# llm_utils.py
import os
from openai import OpenAI
import google.generativeai as genai
from dotenv import load_dotenv

# âœ… .env ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv()

# âœ… í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    raise ValueError("âŒ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")

google_api_key = os.getenv("GOOGLE_API_KEY")
if not google_api_key:
    raise ValueError("âŒ GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")

# âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(api_key=api_key)

# âœ… Google AI ì´ˆê¸°í™”
genai.configure(api_key=google_api_key)


# ğŸ”¹ ì„ë² ë”© í•¨ìˆ˜ (Google ì„ë² ë”© ì‚¬ìš© - ë²¡í„° DBì™€ ë™ì¼í•œ ëª¨ë¸)
def get_embedding(text):
    try:
        result = genai.embed_content(
            model="models/text-embedding-004",
            content=text,
            task_type="RETRIEVAL_QUERY"
        )
        return result['embedding']
    except Exception as e:
        print(f"ì„ë² ë”© ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None


# ğŸ”¹ ê°ì • ì¶”ì¶œ í•¨ìˆ˜
def extract_emotion(user_input: str) -> str:
    prompt = f"""
    ë‹¤ìŒ ë¬¸ì¥ì—ì„œ ê°€ì¥ ë‘ë“œëŸ¬ì§€ëŠ” í•µì‹¬ ê°ì • í•œ ê°€ì§€ë¥¼ 
    'í–‰ë³µ', 'ìŠ¬í””', 'ë¶„ë…¸', 'í‰ì˜¨', 'ë¶ˆì•ˆ' ì¤‘ì—ì„œ í•˜ë‚˜ë§Œ ê³¨ë¼ì£¼ì„¸ìš”.
    ë‹¤ë¥¸ ì„¤ëª… ì—†ì´ ê°ì • ë‹¨ì–´ë§Œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤.

    ë¬¸ì¥: "{user_input}"
    ê°ì •:
    """
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"ê°ì • ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return "í‰ì˜¨"


# ğŸ”¹ ìœ„ë¡œ ë©”ì‹œì§€ ìƒì„± í•¨ìˆ˜
def generate_comforting_message(user_emotion: str, content: dict) -> str:
    content_type = list(content.keys())[0]
    content_name = content[content_type]

    prompt = f"""
    ì‚¬ìš©ìëŠ” í˜„ì¬ '{user_emotion}'ì˜ ê°ì •ì„ ëŠë¼ê³  ìˆìŠµë‹ˆë‹¤.
    ì´ ì‚¬ìš©ìì—ê²Œ ë”°ëœ»í•œ ìœ„ë¡œì™€ ê³µê°ì˜ ë§ì„ ì „í•´ì£¼ì„¸ìš”.
    ê·¸ë¦¬ê³  ì‚¬ìš©ìì˜ í˜„ì¬ ê°ì •ê³¼ ë‹¤ë¥¸ ìƒˆë¡œìš´ ê²½í—˜ì„ í•  ìˆ˜ ìˆë„ë¡,
    '{content_name}'({content_type})ì„(ë¥¼) ì¶”ì²œí•´ì£¼ì„¸ìš”.
    ì¶”ì²œí•˜ëŠ” ì´ìœ ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…í•˜ë©° ë©”ì‹œì§€ë¥¼ ë§ˆë¬´ë¦¬í•´ì£¼ì„¸ìš”.
    ì‘ë‹µì€ í•œêµ­ì–´ë¡œ, ì¹œê·¼í•˜ê³  ë‹¤ì •í•œ ë§íˆ¬ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
    """
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"ë©”ì‹œì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return "ê´œì°®ì•„ìš”, ëª¨ë“  ê²Œ ë‹¤ ì˜ ë  ê±°ì˜ˆìš”. ì˜¤ëŠ˜ í•˜ë£¨ë„ ì •ë§ ê³ ìƒ ë§ìœ¼ì…¨ì–´ìš”."


# ğŸ”¹ ìºë¦­í„°ë³„ ì‘ë‹µ ìƒì„± í•¨ìˆ˜
def generate_character_response(character: str, user_emotion: str, content: dict) -> str:
    """
    ìºë¦­í„° ë§íˆ¬ë¥¼ ë°˜ì˜í•œ ìœ„ë¡œ ë©”ì‹œì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    from prompt.characters import get_character_prompt

    # ì½˜í…ì¸  ì •ë³´ ì¶”ì¶œ
    if "error" in content:
        content_description = "ì¶”ì²œí•  ì½˜í…ì¸ ê°€ ì—†ì–´ìš”."
    else:
        content_type = list(content.keys())[0]
        content_name = content[content_type]
        content_description = f"{content_name} ({content_type})"

    # ìºë¦­í„° í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°
    character_prompt = get_character_prompt(character)

    # ì „ì²´ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    system_prompt = character_prompt
    user_prompt = f"""
    ì‚¬ìš©ìëŠ” í˜„ì¬ '{user_emotion}'ì˜ ê°ì •ì„ ëŠë¼ê³  ìˆìŠµë‹ˆë‹¤.
    ë‹¹ì‹ ì˜ ìºë¦­í„°ì— ë§ëŠ” ë§íˆ¬ë¡œ ì‚¬ìš©ìë¥¼ ë”°ëœ»í•˜ê²Œ ìœ„ë¡œí•˜ê³ ,
    '{content_description}'ì„(ë¥¼) ì¶”ì²œí•´ì£¼ì„¸ìš”.

    ìºë¦­í„°ì˜ íŠ¹ì§•ì„ ì˜ ì‚´ë ¤ì„œ ìì—°ìŠ¤ëŸ½ê³  ì§„ì •ì„± ìˆëŠ” ë©”ì‹œì§€ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
    ì‘ë‹µì€ í•œêµ­ì–´ë¡œ 3-5ë¬¸ì¥ ì •ë„ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
    """

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ]
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"ìºë¦­í„° ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return "ê´œì°®ì•„ìš”, ëª¨ë“  ê²Œ ë‹¤ ì˜ ë  ê±°ì˜ˆìš”. ì˜¤ëŠ˜ í•˜ë£¨ë„ ì •ë§ ê³ ìƒ ë§ìœ¼ì…¨ì–´ìš”."


# ğŸ”¹ ê°„ë‹¨ ì‘ë‹µ í•¨ìˆ˜
def get_llm_answer(user_sentence: str) -> str:
    try:
        prompt = f"ë‹¤ìŒ ë¬¸ì¥ì— ëŒ€í•´ ê³µê°í•˜ê³  ì§§ê²Œ ë‹µí•´ì£¼ì„¸ìš”(í•œêµ­ì–´): \"{user_sentence}\""
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"LLM ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        return "ì ì‹œ ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
