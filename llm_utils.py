# llm_utils.py
import os
from openai import OpenAI
from dotenv import load_dotenv

# âœ… .env ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv()

# âœ… í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    raise ValueError("âŒ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")

# âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(api_key=api_key)


# ğŸ”¹ ì„ë² ë”© í•¨ìˆ˜
def get_embedding(text, model="text-embedding-3-small"):
    try:
        response = client.embeddings.create(
            model=model,
            input=text
        )
        return response.data[0].embedding
    except Exception as e:
        print(f"ì„ë² ë”© ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None


# ğŸ”¹ ê°ì • ì¶”ì¶œ í•¨ìˆ˜
def extract_emotion(user_input: str) -> str:
    prompt = f"""
    ë‹¤ìŒ ë¬¸ì¥ì—ì„œ ê°€ì¥ ë‘ë“œëŸ¬ì§€ëŠ” í•µì‹¬ ê°ì • í•œ ê°€ì§€ë¥¼ 
    'í–‰ë³µ', 'ìŠ¬í””', 'ë¶„ë…¸', 'í‰ì˜¨', 'ë¶ˆì•ˆ' ì¤‘ì—ì„œ í•˜ë‚˜ë§Œ ê³¨ë¼ì£¼ì„¸ìš”.
    ë‹¤ë¥¸ ì„¤ëª… ì—†ì´ ê°ì • ë‹¨ì–´ë§Œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤.

    ë¬¸ì¥: "{user_input}"
    ê°ì •:
    """
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"ê°ì • ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return "í‰ì˜¨"


# ğŸ”¹ ìœ„ë¡œ ë©”ì‹œì§€ ìƒì„± í•¨ìˆ˜
def generate_comforting_message(user_emotion: str, content: dict) -> str:
    content_type = list(content.keys())[0]
    content_name = content[content_type]

    prompt = f"""
    ì‚¬ìš©ìëŠ” í˜„ì¬ '{user_emotion}'ì˜ ê°ì •ì„ ëŠë¼ê³  ìˆìŠµë‹ˆë‹¤.
    ì´ ì‚¬ìš©ìì—ê²Œ ë”°ëœ»í•œ ìœ„ë¡œì™€ ê³µê°ì˜ ë§ì„ ì „í•´ì£¼ì„¸ìš”.
    ê·¸ë¦¬ê³  ì‚¬ìš©ìì˜ í˜„ì¬ ê°ì •ê³¼ ë‹¤ë¥¸ ìƒˆë¡œìš´ ê²½í—˜ì„ í•  ìˆ˜ ìˆë„ë¡,
    '{content_name}'({content_type})ì„(ë¥¼) ì¶”ì²œí•´ì£¼ì„¸ìš”.
    ì¶”ì²œí•˜ëŠ” ì´ìœ ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…í•˜ë©° ë©”ì‹œì§€ë¥¼ ë§ˆë¬´ë¦¬í•´ì£¼ì„¸ìš”.
    ì‘ë‹µì€ í•œêµ­ì–´ë¡œ, ì¹œê·¼í•˜ê³  ë‹¤ì •í•œ ë§íˆ¬ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
    """
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"ë©”ì‹œì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return "ê´œì°®ì•„ìš”, ëª¨ë“  ê²Œ ë‹¤ ì˜ ë  ê±°ì˜ˆìš”. ì˜¤ëŠ˜ í•˜ë£¨ë„ ì •ë§ ê³ ìƒ ë§ìœ¼ì…¨ì–´ìš”."


# ğŸ”¹ ê°„ë‹¨ ì‘ë‹µ í•¨ìˆ˜
def get_llm_answer(user_sentence: str) -> str:
    try:
        prompt = f"ë‹¤ìŒ ë¬¸ì¥ì— ëŒ€í•´ ê³µê°í•˜ê³  ì§§ê²Œ ë‹µí•´ì£¼ì„¸ìš”(í•œêµ­ì–´): \"{user_sentence}\""
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"LLM ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        return "ì ì‹œ ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
